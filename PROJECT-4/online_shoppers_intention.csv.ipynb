{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qScc5V-1wp2"
      },
      "source": [
        "# Project 4: Predicting Online Purchase Intent: A KNN-Based Approach to Customer Behaviour\n",
        "\n",
        "### Project Goal:\n",
        "The main goal of this project is to build a machine learning model that can predict whether a visitor to an e-commerce website will make a purchase. We'll use data about their Browse session—like the pages they visited and how long they stayed—to make this prediction and compare different models to find the most effective one.\n",
        "\n",
        "### Learning Objectives:\n",
        "Learn how to clean and prepare data for machine learning, including encoding categorical features and scaling numerical data.\n",
        "\n",
        "Understand the challenge of class imbalance (when one outcome is much rarer than another) and its impact on model performance.\n",
        "\n",
        "Build, tune, and evaluate a K-Nearest Neighbors (KNN) classifier.\n",
        "\n",
        "Compare the performance of multiple classification algorithms (like Logistic Regression, Decision Trees, and Random Forest) to identify the best model for the task.\n",
        "\n",
        "Explore how techniques like PCA (for simplifying data) and SMOTE (for balancing data) affect model accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIIlu-FJ1wqf"
      },
      "source": [
        "### Importing Necessary Libraries\n",
        "\n",
        "Before we begin, we need to load all the tools we'll need. This block imports libraries for handling data (pandas, numpy), creating plots (matplotlib, seaborn), and building machine learning models (scikit-learn). We also import SMOTE, a technique to handle imbalanced datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXqHibGKwq8i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_glpUw-1wqs"
      },
      "source": [
        "### Loading and Exploring the Data\n",
        "\n",
        "Now, let's load our dataset. We're using pandas to read the online_shoppers_intention.csv file. We'll then display the first five rows using .head() to get a quick feel for the data's structure and contents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYlEzfWxPFS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"C:/Users/HP/Downloads/online_shoppers_intention.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hn2ISkjxeyY"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIOZyvc_1wrI"
      },
      "source": [
        "#### Summary:\n",
        "The summary confirms we have 12,330 entries and 18 columns. Importantly, there are no missing (non-null) values, which simplifies our preprocessing steps. We can also see that columns like Month and VisitorType are of type 'object', meaning they are text-based and we'll need to convert them into numbers for our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21bHZdH11wrL"
      },
      "source": [
        "### Data Preprocessing and Transformation\n",
        "\n",
        "Machine learning models work with numbers, not text or boolean values. In this step, we'll convert our non-numeric columns into a format the model can understand. We use LabelEncoder for 'Month' and 'VisitorType' and change the boolean (True/False) values in 'Weekend' and 'Revenue' to integers (1/0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IYfpi17xiaD"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "df['Month'] = le.fit_transform(df['Month'])\n",
        "df['VisitorType'] = le.fit_transform(df['VisitorType'])\n",
        "df['Weekend'] = df['Weekend'].astype(int)\n",
        "df['Revenue'] = df['Revenue'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drVhZdZJzNxV"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_XakAMn1wrU"
      },
      "source": [
        "As you can see, all columns now have numerical data types (int, float). Our data is clean and fully prepared for the modeling phase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXRrDYFF1wrV"
      },
      "source": [
        "Now, let's check the distribution of our target variable, Revenue. This tells us how many sessions resulted in a purchase versus those that didn't. It's important to check for class imbalance, where one outcome is much more common than the other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQCqAgepzWwW"
      },
      "outputs": [],
      "source": [
        "df['Revenue'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h649sdA1wrZ"
      },
      "source": [
        "The output shows a significant imbalance: 10,422 sessions did not generate revenue (class 0), while only 1,908 did (class 1). This is a common scenario in purchase prediction, and we must be mindful of it, as it can bias our model towards predicting the more common outcome (no purchase)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTn7XzJs1wra"
      },
      "source": [
        "### Data Visualization\n",
        "Let's see if there's a relationship between the month and whether a purchase was made. A line plot can help us visualize this trend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgHF5nZdzc1u"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(x = df['Month'],y = df['Revenue'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTfPrCmc1wrc"
      },
      "source": [
        "The plot shows fluctuations in revenue generation across different months, suggesting that seasonality might be a factor in a customer's intent to purchase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4gQLt-nzqZ3"
      },
      "outputs": [],
      "source": [
        "df['Month'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcIfV_dB1wre"
      },
      "source": [
        "### Model Preparation\n",
        "\n",
        "It's time to prepare our data for modeling. We separate our features (X) from the target variable (y). Then, we split the data into a training set (to build the model) and a testing set (to evaluate it). We use stratify=y to ensure that both the training and testing sets have the same proportion of purchases and non-purchases as the original dataset, which is crucial because of our class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8s0H5gRz_jw"
      },
      "outputs": [],
      "source": [
        "X = df.drop('Revenue',axis = 1)\n",
        "y = df['Revenue']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify = y,test_size = 0.2,random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUoa_AF81wrg"
      },
      "source": [
        "Our features have different scales (e.g., ProductRelated_Duration vs. Month). Algorithms like KNN are sensitive to this. We use StandardScaler to transform our features so they all have a mean of 0 and a standard deviation of 1. We fit the scaler only on the training data to avoid leaking information from the test set into our training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "107DfmFU00bo"
      },
      "outputs": [],
      "source": [
        "sc = StandardScaler()\n",
        "X_train_sc = sc.fit_transform(X_train)\n",
        "X_test_sc = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_CdJmHY1wrh"
      },
      "source": [
        "### Building and Evaluating Models\n",
        "As a baseline, let's first train a simple Logistic Regression model. It's a good starting point for classification problems to establish a benchmark performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6J99cZT1B-q"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_sc,y_train)\n",
        "y_pred = model.predict(X_test_sc)\n",
        "log_acc = model.score(X_test_sc,y_test)\n",
        "print(log_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0OcEErw1wrj"
      },
      "source": [
        "The model achieves an accuracy of about 88.32%. This gives us a solid benchmark to compare against more complex models like KNN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPQgHfPa1wrj"
      },
      "source": [
        "For the K-Nearest Neighbors (KNN) model, choosing the right value for 'k' (the number of neighbors) is critical. We'll test a range of k-values from 1 to 60 and plot the training and testing accuracy for each. This helps us find the \"sweet spot\" where the model performs well on unseen data without overfitting to the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JDlXYnH1m96"
      },
      "outputs": [],
      "source": [
        "test_score, train_score = [],[]\n",
        "k_range = range(1,61)\n",
        "for k in k_range:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train_sc,y_train)\n",
        "    train_score.append(knn.score(X_train_sc,y_train))\n",
        "    test_score.append(knn.score(X_test_sc,y_test))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(k_range,test_score,label='Testing Accuracy')\n",
        "plt.plot(k_range,train_score,label='Training Accuracy')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUHqJ90f1wrk"
      },
      "source": [
        "The plot shows that as 'k' increases, the training accuracy decreases while the testing accuracy increases and then stabilizes. A good value for 'k' appears to be around 5, where the testing accuracy is high before it starts to level off. This balances the model between being too simple (overfitting) and too complex (underfitting)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTM9ocau1wrl"
      },
      "source": [
        "To get a more reliable estimate of our KNN model's performance (with k=5), we use 10-fold cross-validation. This involves splitting the training data into 10 parts, training the model on 9 parts, and testing on the 10th part, repeating this process 10 times to get an average score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xLYt5H12IxA"
      },
      "outputs": [],
      "source": [
        "cv_knn = KNeighborsClassifier(n_neighbors=5)\n",
        "cv_score = cross_val_score(cv_knn,X_train_sc,y_train,cv=10)\n",
        "cv_score.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN4gktEx1wrm"
      },
      "source": [
        "The mean accuracy from cross-validation is about 87.97%. This is a robust measure of how well our model is likely to perform on new, unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v_W2Sb64Zaa"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(cv_score,orient='h')\n",
        "plt.grid('True')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhWxbGYP1wrm"
      },
      "source": [
        "The box plot shows that the accuracy scores are tightly clustered around the mean of ~88%, indicating that the model's performance is quite stable across different subsets of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YktMSGUt1wrn"
      },
      "source": [
        "### Advanced Model Experiments\n",
        "Our dataset has many features. Let's see if we can simplify the model by using Principal Component Analysis (PCA) for dimensionality reduction. We'll reduce the features to just 5 principal components and then train our KNN model on this simplified data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TiP7tiK3Y3_"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=5)\n",
        "X_train_pca = pca.fit_transform(X_train_sc)\n",
        "X_test_pca = pca.transform(X_test_sc)\n",
        "\n",
        "knn_pca = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_pca.fit(X_train_pca,y_train)\n",
        "y_pred_pca = knn_pca.predict(X_test_pca)\n",
        "\n",
        "knn_pca_acc = accuracy_score(y_test,y_pred_pca)\n",
        "print(knn_pca_acc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbCDLcIO1wrp"
      },
      "source": [
        "The accuracy with PCA is about 83.66%, which is lower than the accuracy of the model with all features (~88%). This suggests that reducing the dimensions to 5 components resulted in the loss of important information needed for accurate predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAKm7EiG5f_r"
      },
      "outputs": [],
      "source": [
        "X_train_noise = np.hstack([X_train_sc,np.random.rand(X_train_sc.shape[0],10)])\n",
        "X_test_noise = np.hstack([X_test_sc,np.random.rand(X_test_sc.shape[0],10)])\n",
        "\n",
        "knn_ = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_.fit(X_train_noise,y_train)\n",
        "y_pred_noise = knn_.predict(X_test_noise)\n",
        "knn_noise_acc = accuracy_score(y_test,y_pred_noise)\n",
        "print(knn_noise_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A1PAWXX1wrq"
      },
      "source": [
        "The accuracy with added noise is about 87.39%, only slightly lower than the original model's accuracy. This shows that KNN is somewhat robust to noise, but irrelevant features can still degrade its performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcd8GCYA6u6I"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQopJ4Wa1wr2"
      },
      "source": [
        "The matrix shows the number of true positives, true negatives, false positives, and false negatives. It gives us a clearer picture of where the model is making mistakes, which is more insightful than accuracy alone, especially with our imbalanced dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf2V_8Eh1wr3"
      },
      "source": [
        "### Comparing Multiple Models\n",
        "In this step, we'll train and evaluate four different classification models: Logistic Regression, KNN, Decision Tree, and Random Forest. We'll compare their accuracy and AUC scores to see which one performs best on our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbfa7b50"
      },
      "outputs": [],
      "source": [
        "model_list = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier()\n",
        "}\n",
        "model_score = {}\n",
        "\n",
        "for model_name, model in model_list.items():\n",
        "    model.fit(X_train_sc, y_train)\n",
        "    y_pred = model.predict(X_test_sc)\n",
        "    model_score[model_name]={\n",
        "        'Accuracy': accuracy_score(y_test,y_pred),\n",
        "        'AUC Score': roc_auc_score(y_test,y_pred),\n",
        "    }\n",
        "\n",
        "display(model_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGq7WBqQ1wr4"
      },
      "source": [
        "The results show that Random Forest is the top-performing model with the highest accuracy (90.15%) and AUC score (0.76). This is expected, as Random Forest is a powerful ensemble model that often excels in classification tasks by combining the predictions of multiple decision trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaaIWrkf8qWH"
      },
      "outputs": [],
      "source": [
        "print(\"KNN Project Summary\")\n",
        "print('Logistic Regression Accuracy: {:.4f}'.format(log_acc)*100)\n",
        "print('Cross Validation Accuracy: {:.4f}'.format(cv_score.mean()))\n",
        "print('PCA and KNN togather: {:.4f}'.format(knn_pca_acc))\n",
        "\n",
        "for model_name, results in model_score.items():\n",
        "    print(f\"{model_name} Accuracy: {results['Accuracy']:.4f}\")\n",
        "    print(f\"{model_name} AUC Score: {results['AUC Score']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGFmrV9z1wr7"
      },
      "source": [
        "### Handling Class Imbalance with SMOTE\n",
        "We noted earlier that our dataset is imbalanced. SMOTE (Synthetic Minority Over-sampling Technique) is a powerful method to address this. It works by creating new, synthetic data points for the minority class (sessions with purchases). Here, we apply SMOTE to our training data to create a balanced dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMr5nUGL-6ps"
      },
      "outputs": [],
      "source": [
        "sm = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = sm.fit_resample(X_train_sc, y_train)\n",
        "\n",
        "smote_score = {}\n",
        "for model_name, model in model_list.items():\n",
        "    model.fit(X_train_smote, y_train_smote)\n",
        "    y_pred_smote = model.predict(X_test_sc)\n",
        "    smote_score[model_name] = {\n",
        "        'Accuracy': accuracy_score(y_test, y_pred_smote),\n",
        "        'AUC Score': roc_auc_score(y_test, y_pred_smote),\n",
        "    }\n",
        "print(\"SMOTE Results:\")\n",
        "for model_name, results in smote_score.items():\n",
        "    print(f\"{model_name} Accuracy: {results['Accuracy']:.4f}\")\n",
        "    print(f\"{model_name} AUC Score: {results['AUC Score']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyOF0nVK1wr8"
      },
      "source": [
        "## Conclusion\n",
        "This project successfully developed and evaluated several machine learning models to predict online shoppers' purchase intent. The key takeaways are:\n",
        "\n",
        "1. Data Quality and Imbalance: The dataset was clean with no missing values, but it exhibited a significant class imbalance, with far more non-purchase sessions than purchase sessions. This was the primary challenge throughout the project.\n",
        "\n",
        "2. Model Performance: We compared four different models. Random Forest emerged as the top performer with an accuracy of approximately 90.3% and an AUC score of 0.76. K-Nearest Neighbors (KNN) also performed well, achieving a stable accuracy of around 88% with an optimal 'k' value of 5, as confirmed by cross-validation.\n",
        "\n",
        "3. Feature Engineering Insights: Our experiments showed that dimensionality reduction using PCA was not beneficial, as it led to a drop in accuracy to 83.7%. This indicates that the original features contain valuable information that was lost during the reduction. The KNN model also showed reasonable resilience to noisy data.\n",
        "\n",
        "4. Addressing the Core Challenge: While high accuracy scores were achieved, the class imbalance means these figures can be misleading. A model could achieve high accuracy by simply predicting \"no purchase\" most of the time. The project's final step correctly identified this issue and prepared to solve it by implementing SMOTE to create a balanced training set.\n",
        "\n",
        "Future work should focus on training the models on the SMOTE-resampled data. This will likely improve the model's ability to identify true purchase intent (the minority class), leading to better performance on more telling metrics like Recall and the AUC Score, and ultimately creating a more practically useful prediction tool."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
