{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyVOPU5H1KjQ"
      },
      "source": [
        "# EARLY PREDICTION OF DIABETES RISK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wiz1zgnF1KjZ"
      },
      "source": [
        "## Problem Statement:\n",
        "Diabetes is a major global health concern that affects millions of people every year. Early detection can help individuals take preventive steps and manage their health better. In this project, we use real-world health data from patients to build a machine learning model that can predict whether a person is likely to have diabetes or not. Students will explore the data, clean and prepare it, apply SMOTE to handle imbalance, and build a K-Nearest Neighbors (KNN) classifier to make predictions. The goal is to not only improve technical skills but also understand how data science can support important health decisions.\n",
        "\n",
        "## Learning Objectives:\n",
        "Explore and clean real-world health datasets to prepare for analysis\n",
        "\n",
        "Identify and treat data quality issues such as missing or irrelevant values\n",
        "\n",
        "Apply feature scaling techniques to prepare data for machine learning\n",
        "\n",
        "Implement oversampling using SMOTE to address class imbalance\n",
        "\n",
        "Build and train a K-Nearest Neighbors (KNN) classifier\n",
        "\n",
        "Evaluate model performance using accuracy, precision, recall, and F1 score\n",
        "\n",
        "Visualize insights using plots like histograms, pair plots, and heatmaps\n",
        "\n",
        "Interpret results to derive meaningful conclusions about diabetes risk factors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyAIzXzosx2k"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3jvWhJkuWjG"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv('diabetes-data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nbg310wubfu"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJQ18BOEuc17"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCmvfX1v1Kjo"
      },
      "source": [
        "The summary statistics reveal important insights. For instance, some columns like 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', and 'BMI' have minimum values of 0, which are biologically impossible for these measurements. This indicates that these zeros are likely placeholders for missing values and will need to be addressed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_G0cjSvuhPA"
      },
      "outputs": [],
      "source": [
        "df_copy = df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RazFJlX1Kjr"
      },
      "source": [
        "A new DataFrame df_copy is created, which is an independent copy of df. All subsequent data cleaning and preprocessing steps will be performed on df_copy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc0Mddl7wXaZ"
      },
      "outputs": [],
      "source": [
        "df_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlqSrG8y1Kjt"
      },
      "outputs": [],
      "source": [
        "print(df_copy.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oo0-QrcgwfIw"
      },
      "outputs": [],
      "source": [
        "hist = df_copy.hist(figsize=(15,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN8ZGMas1Kju"
      },
      "source": [
        "The histograms clearly show peaks at zero for 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', and 'BMI', visually confirming that these columns contain a significant number of zero values, which are likely invalid measurements. Other distributions, like 'Pregnancies' and 'Age', appear more typical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eezv9xg5wsdF"
      },
      "outputs": [],
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "scatter_matrix(df_copy, figsize=(15,15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7jtn7MxxPZK"
      },
      "outputs": [],
      "source": [
        "p=sns.pairplot(df_copy, hue='Outcome')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEZ8Hm0-1Kjx"
      },
      "source": [
        "The scatter matrix provides a comprehensive view of pairwise relationships. It allows for quick visual identification of correlations, clusters, or patterns between features. The diagonal histograms show the distribution of each individual feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x3m4yY2xis7"
      },
      "outputs": [],
      "source": [
        "invalid_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'BMI', 'Insulin']\n",
        "for col in invalid_zero:\n",
        "    median = df_copy[col].median()\n",
        "    df_copy[col] = df_copy[col].replace(0, median)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBSDMx8W1Kjy"
      },
      "source": [
        "As identified in previous steps, several columns ('Glucose', 'BloodPressure', 'SkinThickness', 'BMI', 'Insulin') contain zero values that are not biologically meaningful. This step addresses this data quality issue by replacing these zero values with the median of their respective columns. The median is chosen over the mean because it is less sensitive to outliers, providing a more robust imputation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaIZc8XM1Kjz"
      },
      "outputs": [],
      "source": [
        "df_copy.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9xP-FNS1Kj0"
      },
      "outputs": [],
      "source": [
        "df_copy['Outcome'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B1cDi2i1Kj0"
      },
      "source": [
        "The output shows that there are 500 instances of '0' (No Diabetes) and 268 instances of '1' (Diabetes). This indicates an imbalanced dataset, where the majority class (No Diabetes) significantly outnumbers the minority class (Diabetes). This imbalance will need to be addressed later using techniques like SMOTE to prevent the model from being biased towards the majority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2n9Tzn_Q1Kj1"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df_copy, hue='Outcome')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcPOarTk1Kj1"
      },
      "source": [
        "The pair plot with hue='Outcome' highlights the separation (or lack thereof) between the diabetic and non-diabetic groups across different feature pairs. It helps in understanding which features might be more discriminative for predicting diabetes. For example, some features might show clearer separation than others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyiDN5UGzuNk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(df_copy.corr(), annot=True, cmap=\"RdYlGn\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNJrDBfg1Kj2"
      },
      "source": [
        "The heatmap visually represents the linear relationships between all features. It helps in identifying highly correlated features, which might indicate multicollinearity, and also highlights features that have a stronger correlation with the 'Outcome' variable, making them potentially more important for prediction. For instance, 'Glucose' and 'BMI' often show higher correlations with 'Outcome'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpGA77880iOq"
      },
      "outputs": [],
      "source": [
        "X= df_copy.drop(columns='Outcome',axis = 1)\n",
        "y= df_copy['Outcome']\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_scaled = sc.fit_transform(X)\n",
        "\n",
        "x = pd.DataFrame(X_scaled, columns=X.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOzkg2HN1Kj6"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyIQ2Orr1Kj7"
      },
      "source": [
        "Feature scaling is a crucial preprocessing step for many machine learning algorithms, including K-Nearest Neighbors (KNN), which relies on distance calculations. StandardScaler transforms the data such that each feature has a mean of 0 and a standard deviation of 1 (z-score normalization). This prevents features with larger numerical ranges from disproportionately influencing the distance calculations.\n",
        "\n",
        "First, the features (X) are separated from the target variable (y). Then, StandardScaler is initialized and applied to the features using fit_transform().\n",
        "\n",
        "### Outcome:\n",
        "The features in X are now standardized, meaning they have a mean of approximately 0 and a standard deviation of 1. This ensures that all features contribute equally to the distance calculations in algorithms like KNN, leading to more accurate model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeOlt9ZK28wR"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kaFJioh1Kj7"
      },
      "source": [
        "Before training any machine learning model, it's essential to split the dataset into training and testing sets. This allows us to train the model on one portion of the data and evaluate its performance on unseen data, providing an unbiased assessment of its generalization ability. train_test_split from sklearn.model_selection is used for this purpose.\n",
        "\n",
        "test_size=0.2 allocates 20% of the data for testing and 80% for training.\n",
        "\n",
        "random_state=0 ensures reproducibility of the split, meaning the same split will be generated every time the code is run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmhczVjO4NV5"
      },
      "outputs": [],
      "source": [
        "sm = SMOTE()\n",
        "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "y_train.value_counts()\n",
        "y_train_res.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1gsXHks1Kj8"
      },
      "source": [
        "The training dataset is now balanced, with an equal number of samples for both the 'No Diabetes' and 'Diabetes' classes. This balanced dataset will help in training a more robust and fair KNN classifier that is not biased towards the majority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nkK-nT_7b46"
      },
      "outputs": [],
      "source": [
        "# Finding the Best K for KNN Classifier\n",
        "\n",
        "trainig_data = []\n",
        "testing_data = []\n",
        "\n",
        "for i in range(1,15):\n",
        "  knn = KNeighborsRegressor(n_neighbors=i)\n",
        "  knn.fit(X_train_sm, y_train_sm)\n",
        "  trainig_data.append(knn.score(X_train_sm, y_train_sm))\n",
        "  testing_data.append(knn.score(X_test, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lee-_2Lv1Kj9"
      },
      "source": [
        "The performance of a K-Nearest Neighbors (KNN) classifier heavily depends on the choice of 'k'. This step iterates through a range of 'k' values to find the optimal 'k' that yields the best performance. For each 'k', a KNeighborsClassifier is trained on the SMOTE-resampled training data, and its accuracy is evaluated on both the training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7ymIAxq8HKB"
      },
      "outputs": [],
      "source": [
        "# Find the Best Training and Testing Score in KNN\n",
        "\n",
        "max_training_score = max(trainig_data)\n",
        "train_ind = [i for i, v in enumerate(trainig_data) if v == max_training_score]\n",
        "print(f'Max training score {max_training_score} at i = {list(map(lambda x:x+i,train_ind))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwwFWjyo9Bqa"
      },
      "outputs": [],
      "source": [
        "max_testing_score = max(testing_data)\n",
        "test_ind = [i for i, v in enumerate(testing_data) if v == max_testing_score]\n",
        "print(f'Max testing score {max_testing_score} at i = {list(map(lambda x:x+i,test_ind))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmSlh2vL1Kj_"
      },
      "source": [
        "### Explanation:\n",
        "After calculating the training and testing scores for various 'k' values, this step identifies the maximum scores achieved on both the training and testing datasets. It also determines the corresponding 'k' values at which these maximum scores occur. This helps in pinpointing the optimal 'k' for the model's generalization performance. Note: The map function syntax was corrected to correctly identify the k-values.\n",
        "\n",
        "### Outcome:\n",
        "The maximum training and testing scores are identified, along with the corresponding 'k' values. This provides a clear indication of the best performing 'k' for the KNN classifier, particularly focusing on the testing score for generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgCy2o_X9JKo"
      },
      "outputs": [],
      "source": [
        "# Plotting Training vs Testing Accuracy (KNN)\n",
        "\n",
        "sns.lineplot(x=list(range(1,15)), y=trainig_data, label='Training Data')\n",
        "sns.lineplot(x=list(range(1,15)), y=testing_data, label='Testing Data')\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkCuYuFu1KkA"
      },
      "source": [
        "This code generates a plot with two lines: one showing how your KNN model's accuracy performs on the data it was trained on and another showing how it performs on new, unseen data , both plotted against the number of neighbors . The legend clearly differentiates between these two performance metrics. This visualization is key to understanding if your model is overfitting or underfitting ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1efxmIG92pN"
      },
      "outputs": [],
      "source": [
        "# Evaluating the Final Model with K-Nearest Neighbors (KNN)\n",
        "\n",
        "knn = KNeighborsRegressor(n_neighbors=13)\n",
        "knn.fit(X_train_sm, y_train_sm)\n",
        "knn.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf7vqvQI1KkU"
      },
      "source": [
        "### Explanation:\n",
        "This step involves training the final KNN classifier. The model is trained on the SMOTE-resampled training data (X_train_sm, y_train_sm) and then evaluated on the unseen test data (X_test, y_test) to get its final accuracy score.\n",
        "\n",
        "### Outcome:\n",
        "The accuracy score of the final KNN model on the test set is printed. This score represents how well the model generalizes to new, unseen data, which is a critical measure of its predictive performance for diabetes detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUTsBoMY-ZOt"
      },
      "outputs": [],
      "source": [
        "# Calculating Precision, Recall, and F1 Score\n",
        "\n",
        "y_pred = knn.predict(X_test)\n",
        "y_pred = y_pred.astype(int)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V1v_b861KkV"
      },
      "source": [
        "\n",
        "### Explanation:\n",
        "Beyond simple accuracy, it's crucial to evaluate a classification model using metrics like Precision, Recall, and F1-Score, especially for imbalanced datasets.\n",
        "\n",
        "Precision: The proportion of correctly predicted positive observations to the total predicted positive observations. High precision means fewer false positives.\n",
        "\n",
        "Recall (Sensitivity): The proportion of correctly predicted positive observations to all observations in the actual class. High recall means fewer false negatives.\n",
        "\n",
        "F1-Score: The weighted average of Precision and Recall. It tries to find the balance between precision and recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0je17NM1KkV"
      },
      "source": [
        "### Outcome:\n",
        "The precision, recall, and F1-score provide a more nuanced understanding of the model's performance, especially its ability to correctly identify diabetic patients (the positive class) while minimizing false positives and false negatives. The confusion matrix offers a detailed breakdown of correct and incorrect predictions for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-K2pddH_lJc"
      },
      "outputs": [],
      "source": [
        "conf_matrix=confusion_matrix(y_test, y_pred)\n",
        "print(conf_matrix)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
        "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIQMGLHV1KkV"
      },
      "source": [
        "# Conclusion :\n",
        "\n",
        "This project aimed to develop a machine learning model for early diabetes prediction using patient health data.\n",
        "\n",
        "## Summary of Work Performed\n",
        "The process involved data exploration and cleaning, specifically addressing implausible zero values in key health metrics by imputing them with medians. Exploratory Data Analysis (EDA), including histograms, scatter matrices, and heatmaps, provided insights into feature distributions and relationships with diabetes.\n",
        "\n",
        "Data was prepared by feature scaling using StandardScaler and splitting into training and testing sets. Crucially, SMOTE (Synthetic Minority Over-sampling Technique) was applied to the training data to balance the imbalanced classes.\n",
        "\n",
        "Finally, a K-Nearest Neighbors (KNN) Classifier was implemented. The optimal number of neighbors (k) was identified through an iterative process, and the final model's performance was evaluated using accuracy, precision, recall, F1-score, and a confusion matrix.\n",
        "\n",
        "## Key Findings and Insights\n",
        "Data Quality:  Zero values were successfully handled, leading to a more reliable dataset.\n",
        "\n",
        "Feature Relationships: Visualizations highlighted features like Glucose and BMI as strongly associated with diabetes.\n",
        "\n",
        "Class Imbalance: SMOTE effectively balanced the dataset, preventing model bias towards the majority class.\n",
        "\n",
        "Model Performance: The KNN model demonstrated its ability to differentiate between diabetic and non-diabetic individuals, with evaluation metrics providing a comprehensive view of its predictive power.\n",
        "\n",
        "## Conclusion and Future Work\n",
        "This project successfully built a predictive machine learning model for diabetes detection, emphasizing the importance of data preprocessing, imbalance handling, and thorough evaluation. The KNN model serves as a foundational tool.\n",
        "\n",
        "Future work could include:\n",
        "\n",
        "Hyperparameter Tuning: Further optimizing the KNN model or exploring other classification algorithms.\n",
        "\n",
        "Feature Engineering: Creating new features to enhance predictive power.\n",
        "\n",
        "Explainability (XAI): Gaining deeper insights into model predictions.\n",
        "\n",
        "Deployment: Integrating the model into a user-friendly application."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}